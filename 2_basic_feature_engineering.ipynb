{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-basic-feature-engineering.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNiHSeQ38PLH/9hB0tWweea",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/introduction-to-time-series-forecasting-with-python/blob/part-1-data-preparation/2_basic_feature_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bXpU2vK9GLh",
        "colab_type": "text"
      },
      "source": [
        "# Basic Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilkt1qRx9HCs",
        "colab_type": "text"
      },
      "source": [
        "Time Series data must be re-framed as a supervised learning dataset before we can start using machine learning algorithms. There is no concept of input and output features in time series.\n",
        "\n",
        "Instead, we must choose the variable to be predicted and use feature engineering to construct all of the inputs that will be used to make predictions for future time steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1JDGg2_9bnC",
        "colab_type": "text"
      },
      "source": [
        "## Feature Engineering for Time Series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsRWob6M9ci_",
        "colab_type": "text"
      },
      "source": [
        "A time series dataset must be transformed to be modeled as a supervised learning problem.\n",
        "\n",
        "That is something that looks like:\n",
        "\n",
        "```python\n",
        "time 1, value 1\n",
        "time 2, value 2\n",
        "time 3, value 3\n",
        "```\n",
        "\n",
        "To something that looks like:\n",
        "\n",
        "```python\n",
        "input 1, output 1\n",
        "input 2, output 2\n",
        "input 3, output 3\n",
        "```\n",
        "\n",
        "So that we can train a supervised learning algorithm. Input variables are also called features in the field of machine learning, and the task before us is to create or invent new input features from our time series dataset. Ideally, we only want input features that best help the learning methods model the relationship between the inputs (X) and the outputs (y) that we would like\n",
        "to predict.\n",
        "\n",
        "We will look at three classes of features that we can create from our\n",
        "time series dataset:\n",
        "\n",
        "* **Date Time Features**: these are components of the time step itself for each observation.\n",
        "* **Lag Features**: these are values at prior time steps.\n",
        "* **Window Features**: these are a summary of values over a fixed window of prior time steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RR0l50ko-JBG",
        "colab_type": "text"
      },
      "source": [
        "## Goal of Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-ndveE--J-k",
        "colab_type": "text"
      },
      "source": [
        "The goal of feature engineering is to provide strong and ideally simple relationships between new input features and the output feature for the supervised learning algorithm to model. In effect, we are moving complexity.\n",
        "\n",
        "Complexity exists in the relationships between the input and output data. In the case of time series, there is no concept of input and output variables; we must invent these too and frame the supervised learning problem from scratch.\n",
        "\n",
        "The difficulty is that we do not know the underlying inherent functional relationship between inputs and outputs that we're trying to expose. If we did know, we probably would not need machine learning. Instead, the only feedback we have is the performance of models developed on the supervised learning datasets or views of the problem we create. \n",
        "\n",
        "In effect, the best default strategy is to use all the knowledge available to create many good datasets from your time series dataset and use model performance (and other project requirements) to help determine what good features and good views of your problem happen to be.\n",
        "\n",
        "For clarity, we will focus on a univariate (one variable) time series dataset in the examples, but these methods are just as applicable to multivariate time series problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPIl38AArtZ",
        "colab_type": "text"
      },
      "source": [
        "## Minimum Daily Temperatures Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGvBDAjoAuQY",
        "colab_type": "text"
      },
      "source": [
        "This dataset describes the minimum daily temperatures over 10 years (1981-1990) in the city Melbourne, Australia. The units are in degrees Celsius and there are 3650 observations. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yactGEJ5BCzS",
        "colab_type": "code",
        "outputId": "bad0a631-91ca-4d37-d267-d22d7cfd5faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas import Series\n",
        "from pandas import DataFrame\n",
        "\n",
        "series = pd.read_csv('daily-minimum-temperatures-in-me.csv', header=0, parse_dates=[0], index_col=0, squeeze=True)\n",
        "series.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date\n",
              "1981-01-01    20.7\n",
              "1981-01-02    17.9\n",
              "1981-01-03    18.8\n",
              "1981-01-04    14.6\n",
              "1981-01-05    15.8\n",
              "Name: Daily minimum temperatures in Melbourne, Australia, 1981-1990, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgyoCgj8DIoA",
        "colab_type": "code",
        "outputId": "2d6b82c4-2bdb-4f4a-b548-897686463f74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "dataframe = DataFrame()\n",
        "dataframe['month'] = [series.index[i].month for i in range(len(series))]\n",
        "dataframe['day'] = [series.index[i].day for i in range(len(series))]\n",
        "dataframe['temperature'] = [series.index[i] for i in range(len(series))]\n",
        "print(dataframe.head(5))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   month  day temperature\n",
            "0      1    1  1981-01-01\n",
            "1      1    2  1981-01-02\n",
            "2      1    3  1981-01-03\n",
            "3      1    4  1981-01-04\n",
            "4      1    5  1981-01-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EXZp-c4H_Lm",
        "colab_type": "text"
      },
      "source": [
        "Using just the month and day information alone to predict temperature is not sophisticated and will likely result in a poor model. Nevertheless, this information coupled with additional engineered features may ultimately result in a better model. You may enumerate all the properties of a time-stamp and consider what might be useful for your problem, such as:\n",
        "\n",
        "* Minutes elapsed for the day.\n",
        "* Hour of day.\n",
        "* Business hours or not.\n",
        "* Weekend or not.\n",
        "* Season of the year.\n",
        "* Business quarter of the year.\n",
        "* Daylight savings or not.\n",
        "* Public holiday or not.\n",
        "* Leap year or not.\n",
        "\n",
        "You can use binary ag features as well, like whether or not the observation was recorded on a public holiday. In the case of the minimum temperature dataset, maybe the season would be more relevant. It is creating domain-specific features like this that are more likely to add value to\n",
        "your model. Date-time based features are a good start, but it is often a lot more useful to include the values at previous time steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foVnlQu3IqGR",
        "colab_type": "text"
      },
      "source": [
        "## Lag Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKrgl1nPIvSV",
        "colab_type": "text"
      },
      "source": [
        "Lag features are the classical way that time series forecasting problems are transformed into supervised learning problems. The simplest approach is to predict the value at the next time (t+1) given the value at the current time (t).\n",
        "\n",
        "```python\n",
        "Value(t), Value(t+1)\n",
        "Value(t), Value(t+1)\n",
        "Value(t), Value(t+1)\n",
        "```\n",
        "\n",
        "The Pandas library provides the shift() function1 to help create these shifted or lag features from a time series dataset. Shifting the dataset by 1 creates the t column, adding a NaN (unknown) value for the first row. The time series dataset without a shift represents the t+1.\n",
        "\n",
        "Let's make this concrete with an example. The first 3 values of the temperature dataset are 20.7, 17.9, and 18.8. The shifted and unshifted lists of temperatures for the first 3 observations are therefore:\n",
        "\n",
        "```python\n",
        "Shifted, Original\n",
        "NaN,     20.7\n",
        "20.7,    17.9\n",
        "17.9,    18.8\n",
        "```\n",
        "\n",
        "We can concatenate the shifted columns together into a new DataFrame using the concat() function along the column axis (axis=1). \n",
        "\n",
        "Putting this all together, below is an example of creating a lag feature for our daily temperature dataset. The values are extracted from the\n",
        "loaded series and a shifted and unshifted list of these values is created.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w25DqppqHn-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "ad8f1b7a-55e3-4320-80eb-60a363d1571c"
      },
      "source": [
        "temps = DataFrame(series.values)\n",
        "dataframe = pd.concat([temps.shift(1), temps], axis=1)\n",
        "dataframe.columns = ['t', 't+1']\n",
        "print(dataframe.head())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      t   t+1\n",
            "0   NaN  20.7\n",
            "1  20.7  17.9\n",
            "2  17.9  18.8\n",
            "3  18.8  14.6\n",
            "4  14.6  15.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfAZ0BJ_PgsI",
        "colab_type": "text"
      },
      "source": [
        "You can see that we would have to discard the first row to use the dataset to train a supervised learning model, as it does not contain enough data to work with. The addition of lag features is called the sliding window method, in this case with a window width of 1. It is as though we are sliding our focus along the time series for each observation with an interest in only what is within the window width. We can expand the window width and include more lagged features.\n",
        "\n",
        "For example, below is the above case modified to include the last 3 observed\n",
        "values to predict the value at the next time step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9L3Uo6Q-1Fr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "c90351fc-6361-4ac4-e88b-416125f7b5a7"
      },
      "source": [
        "# create lag features\n",
        "temps = DataFrame(series.values)\n",
        "dataframe = pd.concat([temps.shift(3), temps.shift(2), temps.shift(1), temps], axis=1)\n",
        "dataframe.columns = ['t-2', 't-1', 't', 't+1']\n",
        "print(dataframe.head())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    t-2   t-1     t   t+1\n",
            "0   NaN   NaN   NaN  20.7\n",
            "1   NaN   NaN  20.7  17.9\n",
            "2   NaN  20.7  17.9  18.8\n",
            "3  20.7  17.9  18.8  14.6\n",
            "4  17.9  18.8  14.6  15.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejRTElaaQtbM",
        "colab_type": "text"
      },
      "source": [
        "Again, you can see that we must discard the first few rows that do not have enough data to train a supervised model. A dificulty with the sliding window approach is how large to make the window for your problem. \n",
        "\n",
        "Perhaps a good starting point is to perform a sensitivity analysis and try a suite of different window widths to in turn create a suite of different views of your dataset and see which results in better performing models. There will be a point of diminishing returns.\n",
        "\n",
        "Perhaps you need a lag value from last week, last month, and last year. Again, this comes down to the specific domain. In the case of the\n",
        "temperature dataset, a lag value from the same day in the previous year or previous few years may be useful. We can do more with a window than include the raw values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAy0QULdRWIE",
        "colab_type": "text"
      },
      "source": [
        "## Rolling Window Statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siIcMf7FRXFX",
        "colab_type": "text"
      },
      "source": [
        "A step beyond adding raw lagged values is to add a summary of the values at previous time steps. We can calculate summary statistics across the values in the sliding window and include these as features in our dataset. Perhaps the most useful is the mean of the previous few values, also called the rolling mean.\n",
        "\n",
        "We can calculate the mean of the current and previous values and use that to predict the next value. For the temperature data, we would have to wait 3 time steps before we had 2 values to take the average of before we could use that value to predict a 3rd value.\n",
        "\n",
        "```python\n",
        "mean(t-1, t), t+1\n",
        "mean(20.7, 17.9), 18.8\n",
        "19.3, 18.8\n",
        "```\n",
        "\n",
        "Pandas provides a rolling() function3 that creates a new data structure with the window of values at each time step. We can then perform statistical functions on the window of values collected for each time step, such as calculating the mean. First, the series must be shifted.\n",
        "Then the rolling dataset can be created and the mean values calculated on each window of two values. \n",
        "\n",
        "Here are the values in the first three rolling windows:\n",
        "\n",
        "```python\n",
        "#, Window Values\n",
        "1, NaN\n",
        "2, NaN, 20.7\n",
        "3, 20.7, 17.9\n",
        "```\n",
        "\n",
        "This suggests that we will not have usable data until the 3rd row. Finally, as in the previous section, we can use the concat() function to construct a new dataset with just our new columns.\n",
        "\n",
        "The example below demonstrates how to do this with Pandas with a window size of 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjG7hZGBQNnF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "series = pd.read_csv('daily-minimum-temperatures-in-me.csv', header=0, parse_dates=[0], index_col=0, squeeze=True)\n",
        "temps = DataFrame(series.values)\n",
        "shifted = temps.shift(1)\n",
        "window = shifted.rolling(window=2)\n",
        "means = window.mean().astype(float)\n",
        "dataframe = pd.concat([means, temps], axis=1)\n",
        "dataframe.columns = ['mean(t-1, t)', 't+1']\n",
        "print(dataframe.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBPTGYF5hG0L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "a591e192-f5fe-4760-be63-77946d9f4712"
      },
      "source": [
        "series = pd.read_csv('daily-minimum-temperatures-in-me.csv', header=0, parse_dates=[0], index_col=0, squeeze=True)\n",
        "temps = DataFrame(series.values)\n",
        "window = temps.expanding()\n",
        "dataframe = pd.concat([window.min(), window.mean(), window.max(), temps.shift(-1)], axis=1)\n",
        "dataframe.columns = ['min', 'mean', 'max', 't+1']\n",
        "print(dataframe.head(5))\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "DataError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDataError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-7c5cb08e0803>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtemps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't+1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/window.py\u001b[0m in \u001b[0;36mmin\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2147\u001b[0m         \u001b[0mnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_expanding_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"min\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2148\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2150\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mSubstitution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"expanding\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/window.py\u001b[0m in \u001b[0;36mmin\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0mnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_window_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"min\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"roll_min\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"min\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/window.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, func, name, window, center, check_minp, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/window.py\u001b[0m in \u001b[0;36m_wrap_results\u001b[0;34m(self, results, blocks, obj, exclude)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mDataError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No numeric types to aggregate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDataError\u001b[0m: No numeric types to aggregate"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckAI1vR6lYBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}